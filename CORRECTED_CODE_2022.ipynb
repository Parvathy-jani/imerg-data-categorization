{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "774ac39c-e5aa-48ab-b3e0-3bc2b0ff3947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKING CODE FOR DAILY .NC WITH 49 TIMESTAMPS,ACCUMULATED DAILY CSV FILES\n",
    "# (CODE FOR LOG FILE:Log_2022.txt)\n",
    "import os\n",
    "import glob\n",
    "import xarray as xr\n",
    "import cftime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the base paths\n",
    "imerg_base_path = \"/home/pc/Desktop/IMERG_2022\"\n",
    "output_base_path = \"/home/pc/Desktop/IMERG_OP_2022\"\n",
    "log_file_path = os.path.join(output_base_path, \"log_2022.txt\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_base_path, exist_ok=True)\n",
    "\n",
    "# Define the months you want to process\n",
    "months_to_process = range(3, 11)\n",
    "\n",
    "# Define the years you want to process\n",
    "years_to_process = range(2022, 2023)\n",
    "\n",
    "# Helper function to determine the number of days in a month\n",
    "def days_in_month(year, month):\n",
    "    if month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "        return 31\n",
    "    elif month in [4, 6, 9, 11]:\n",
    "        return 30\n",
    "    elif month == 2:\n",
    "        # Check for leap year\n",
    "        if (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0):\n",
    "            return 29\n",
    "        else:\n",
    "            return 28\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Define rain event categories\n",
    "rain_ranges = {\n",
    "    'Background rain': (0, 7.8),\n",
    "    'Moderate Rain Events': (7.8, 39.4),\n",
    "    'Intense Rain Events': (39.4, 136.6),\n",
    "    'Extreme Rain Events': (136.6, np.inf)\n",
    "}\n",
    "\n",
    "# Function to determine the type of rain event\n",
    "def determine_rain_type(precipitation):\n",
    "    for event, (min_val, max_val) in rain_ranges.items():\n",
    "        if min_val <= precipitation < max_val:\n",
    "            return event\n",
    "    return 'Unknown'\n",
    "\n",
    "# Open the log file\n",
    "with open(log_file_path, 'w') as log_file:\n",
    "    # Write the title to the log file\n",
    "    log_file.write(\"ACCUMULATED RAIN CSV AND .NC FOR YEAR 2022\\n\\n\")\n",
    "    \n",
    "    # Loop over the specified years\n",
    "    for iyear in years_to_process:\n",
    "        # Loop over the specified months\n",
    "        for imonth in months_to_process:\n",
    "            # Determine the number of days in the month\n",
    "            dayend = days_in_month(iyear, imonth)\n",
    "            \n",
    "            # Loop over the days in the month\n",
    "            for iday in range(1, dayend + 1):\n",
    "                # Skip days before March 31\n",
    "                if iyear == 2022 and imonth == 3 and iday < 31:\n",
    "                    continue\n",
    "                \n",
    "                # Create a list to hold the datasets\n",
    "                datasets = []\n",
    "                \n",
    "                # Gather files for the current day and the next day\n",
    "                for iday_offset in [0, 1]:\n",
    "                    current_day = iday + iday_offset\n",
    "                    \n",
    "                    if current_day > dayend:\n",
    "                        # Move to the next month if the day exceeds the current month\n",
    "                        next_month = imonth + 1\n",
    "                        next_day = current_day - dayend\n",
    "                        if next_month > 10:\n",
    "                            next_year = iyear + 1\n",
    "                            next_month = 1\n",
    "                        else:\n",
    "                            next_year = iyear\n",
    "                    else:\n",
    "                        next_year = iyear\n",
    "                        next_month = imonth\n",
    "                        next_day = current_day\n",
    "                        \n",
    "                    log_file.write(f\"{iyear}-{imonth:02d}-{iday:02d}:\\n\")\n",
    "                    log_file.write(f\"{iday_offset}-{current_day:02d}:\\n\")\n",
    "                    log_file.write(f\"{next_year}-{next_month:02d}-{next_day:02d}:\\n\")\n",
    "                    # Construct the file prefix\n",
    "                    file_prefix = f'3B-HHR.MS.MRG.3IMERG.{next_year}{next_month:02d}{next_day:02d}'\n",
    "\n",
    "                    # Find all files with the matching prefix\n",
    "                    file_pattern = os.path.join(imerg_base_path, f\"{file_prefix}*.HDF5.nc4\")\n",
    "                    matching_files = glob.glob(file_pattern)\n",
    "                    \n",
    "                    if not matching_files:\n",
    "                        log_file.write(f\"No files found for prefix: {file_prefix}\\n\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Load each file (example loading using xarray)\n",
    "                    for file_name in sorted(matching_files):\n",
    "                        try:\n",
    "                            ds = xr.open_dataset(file_name)\n",
    "                            datasets.append(ds)\n",
    "                        except Exception as e:\n",
    "                            log_file.write(f\"Error loading {file_name}: {str(e)}\\n\")\n",
    "                    \n",
    "                # Concatenate datasets along the time dimension\n",
    "                if datasets:\n",
    "                    combined_ds = xr.concat(datasets, dim='time')\n",
    "                    \n",
    "                    # Define time slicing parameters\n",
    "                    start_time = cftime.DatetimeJulian(2022, imonth, iday, 3, 0, 0)\n",
    "                    end_time = cftime.DatetimeJulian(next_year, next_month, next_day, 3, 0, 0)\n",
    "                    \n",
    "                    # Perform time slicing\n",
    "                    ds_sliced = combined_ds.sel(time=slice(start_time, end_time))\n",
    "                    \n",
    "                    # Verify the number of time steps\n",
    "                    time_steps = len(ds_sliced.time)\n",
    "                    if time_steps != 49:\n",
    "                        log_file.write(f\"Warning: Expected 49 time steps but found {time_steps} for {start_time} to {end_time}. There might be missing data.\\n\")\n",
    "\n",
    "                    # Log the time range\n",
    "                    log_file.write(f\"Processing time range: {start_time} to {end_time}\\n\")\n",
    "                    \n",
    "                    # Save the accumulated dataset as a .nc file for verification\n",
    "                    accumulated_nc_file = os.path.join(output_base_path, f\"Acc_rainfall_3gmt_{start_time.strftime('%Y%m%d')}_3gmt_{end_time.strftime('%Y%m%d')}.nc\")\n",
    "                    try:\n",
    "                        ds_sliced.to_netcdf(accumulated_nc_file)\n",
    "                        log_file.write(f\"Accumulated dataset saved to: {accumulated_nc_file}\\n\")\n",
    "                    except Exception as e:\n",
    "                        log_file.write(f\"Error saving {accumulated_nc_file}: {str(e)}\\n\")\n",
    "\n",
    "                    # Open the .nc file and log the contents\n",
    "                    try:\n",
    "                        with xr.open_dataset(accumulated_nc_file) as nc_file:\n",
    "                            log_file.write(f\"Contents of {accumulated_nc_file}:\\n\")\n",
    "                            log_file.write(str(nc_file))\n",
    "                            log_file.write('\\n\\n')\n",
    "                    except Exception as e:\n",
    "                        log_file.write(f\"Error opening {accumulated_nc_file}: {str(e)}\\n\")\n",
    "\n",
    "                    # Calculate and save daily accumulated precipitation\n",
    "                    try:\n",
    "                        accumulated_precipitation = ds_sliced['precipitation'].sum(dim='time', skipna=True)\n",
    "                        accumulated_df = accumulated_precipitation.to_dataframe().reset_index()\n",
    "\n",
    "                        # Add rain type column\n",
    "                        accumulated_df['Rain Type'] = accumulated_df['precipitation'].apply(determine_rain_type)\n",
    "                        accumulated_df['Date'] = end_time.strftime('%Y-%m-%d')\n",
    "\n",
    "                        # Define output CSV file path\n",
    "                        output_date = end_time.strftime('%Y-%m-%d')\n",
    "                        accumulated_csv_file = os.path.join(output_base_path, f\"Acc_rainfall_3gmt_{start_time.strftime('%Y-%m-%d')}_3gmt_{end_time.strftime('%Y-%m-%d')}.csv\")\n",
    "                        \n",
    "                        # Save the CSV\n",
    "                        accumulated_df.to_csv(accumulated_csv_file, index=False)\n",
    "                        log_file.write(f\"Saved accumulated precipitation to CSV: {accumulated_csv_file}\\n\")\n",
    "                    except Exception as e:\n",
    "                        log_file.write(f\"Error calculating or saving CSV for {start_time} to {end_time}: {str(e)}\\n\")\n",
    "\n",
    "\n",
    "                    # Close the datasets\n",
    "                    combined_ds.close()\n",
    "                    for ds in datasets:\n",
    "                        ds.close()\n",
    "\n",
    "    log_file.write(\"Processing completed.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5581a59c-80d4-49ef-a463-7ae03ce124fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAILY_ACC_RAIN_.NC FILES ( THE SAME .NC FILES IS CREATED FROM THE ABOVE CODE)\n",
    "#(CODE FOR LOG FILE:Log_2022_Daily_Acc_Rain.txt) \n",
    "import os\n",
    "import glob\n",
    "import xarray as xr\n",
    "import cftime\n",
    "\n",
    "# Define the base paths\n",
    "imerg_base_path = \"/home/pc/Desktop/IMERG_2022\"\n",
    "output_base_path = \"/home/pc/Desktop/IMERG_OP_2022\"\n",
    "log_file_path = os.path.join(output_base_path, \"log_2022_Daily_Acc_Rain.txt\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_base_path, exist_ok=True)\n",
    "\n",
    "# Define the months you want to process\n",
    "months_to_process = range(3, 11)\n",
    "\n",
    "# Define the years you want to process\n",
    "years_to_process = range(2022, 2023)\n",
    "\n",
    "# Helper function to determine the number of days in a month\n",
    "def days_in_month(year, month):\n",
    "    if month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "        return 31\n",
    "    elif month in [4, 6, 9, 11]:\n",
    "        return 30\n",
    "    elif month == 2:\n",
    "        # Check for leap year\n",
    "        if (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0):\n",
    "            return 29\n",
    "        else:\n",
    "            return 28\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Function to perform time slicing and accumulation\n",
    "def slice_and_accumulate(iyear, imonth, iday, log_file):\n",
    "    datasets = []\n",
    "    for iday_offset in [0, 1]:\n",
    "        current_day = iday + iday_offset\n",
    "        if current_day > days_in_month(iyear, imonth):\n",
    "            next_month = imonth + 1\n",
    "            next_day = current_day - days_in_month(iyear, imonth)\n",
    "            if next_month > 10:\n",
    "                next_year = iyear + 1\n",
    "                next_month = 1\n",
    "            else:\n",
    "                next_year = iyear\n",
    "        else:\n",
    "            next_year = iyear\n",
    "            next_month = imonth\n",
    "            next_day = current_day\n",
    "\n",
    "        log_file.write(f\"{iyear}-{imonth:02d}-{iday:02d}:\\n\")\n",
    "        log_file.write(f\"{iday_offset}-{current_day:02d}:\\n\")\n",
    "\n",
    "        file_prefix = f'3B-HHR.MS.MRG.3IMERG.{next_year}{next_month:02d}{next_day:02d}'\n",
    "        file_pattern = os.path.join(imerg_base_path, f\"{file_prefix}*.HDF5.nc4\")\n",
    "        matching_files = glob.glob(file_pattern)\n",
    "\n",
    "        for file_name in sorted(matching_files):\n",
    "            try:\n",
    "                ds = xr.open_dataset(file_name)\n",
    "                datasets.append(ds)\n",
    "            except Exception as e:\n",
    "                log_file.write(f\"Error loading {file_name}: {str(e)}\\n\")\n",
    "\n",
    "    if datasets:\n",
    "        combined_ds = xr.concat(datasets, dim='time')\n",
    "        start_time = cftime.DatetimeJulian(iyear, imonth, iday, 3, 0, 0)\n",
    "        end_time = cftime.DatetimeJulian(next_year, next_month, next_day, 3, 0, 0)\n",
    "        ds_sliced = combined_ds.sel(time=slice(start_time, end_time))\n",
    "\n",
    "        time_steps = len(ds_sliced.time)\n",
    "        if time_steps != 49:\n",
    "            log_file.write(f\"Warning: Expected 49 time steps but found {time_steps} for {start_time} to {end_time}. There might be missing data.\\n\")\n",
    "\n",
    "        try:\n",
    "            accumulated_precipitation = ds_sliced['precipitation'].sum(dim='time', skipna=True)\n",
    "            accumulated_precipitation = accumulated_precipitation.expand_dims('time')\n",
    "            accumulated_precipitation_ds = accumulated_precipitation.to_dataset(name='accumulated_precipitation')\n",
    "            accumulated_precipitation_ds['time'] = [end_time.strftime('%Y-%m-%d')]\n",
    "\n",
    "            daily_nc_file = os.path.join(output_base_path, f\"IMERG_Daily_acc_rainfall_{end_time.strftime('%Y-%m-%d')}.nc\")\n",
    "            accumulated_precipitation_ds.to_netcdf(daily_nc_file)\n",
    "            log_file.write(f\"Saved daily accumulated precipitation to .nc: {daily_nc_file}\\n\")\n",
    "\n",
    "            # Open the .nc file and log the contents and accumulated precipitation values\n",
    "            try:\n",
    "                with xr.open_dataset(daily_nc_file) as nc_file:\n",
    "                    log_file.write(f\"Contents of {daily_nc_file}:\\n\")\n",
    "                    log_file.write(str(nc_file))\n",
    "                    log_file.write('\\n')\n",
    "                    log_file.write(\"Accumulated Precipitation Values:\\n\")\n",
    "                    log_file.write(str(nc_file['accumulated_precipitation'].values))\n",
    "                    log_file.write('\\n\\n')\n",
    "            except Exception as e:\n",
    "                log_file.write(f\"Error opening {daily_nc_file}: {str(e)}\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            log_file.write(f\"Error calculating or saving .nc file for {end_time.strftime('%Y-%m-%d')}: {str(e)}\\n\")\n",
    "\n",
    "        # Log the time range with timestamps\n",
    "        log_file.write(\"Timestamps:\\n\")\n",
    "        log_file.write(f\"Processing time range: {start_time} to {end_time} ({start_time.strftime('%Y-%m-%d %H:%M:%S')} to {end_time.strftime('%Y-%m-%d %H:%M:%S')})\\n\")\n",
    "\n",
    "        for timestamp in ds_sliced.time.values:\n",
    "            log_file.write(f\"{timestamp}\\n\")\n",
    "\n",
    "        combined_ds.close()\n",
    "        for ds in datasets:\n",
    "            ds.close()\n",
    "\n",
    "with open(log_file_path, 'w') as log_file:\n",
    "    log_file.write(\"DAILY_ACCUMULATED_RAINFALL.NC FOR YEAR 2022\\n\\n\")\n",
    "\n",
    "    for iyear in years_to_process:\n",
    "        for imonth in months_to_process:\n",
    "            dayend = days_in_month(iyear, imonth)\n",
    "\n",
    "            for iday in range(1, dayend + 1):\n",
    "                if iyear == 2022 and imonth == 3 and iday < 31:\n",
    "                    continue\n",
    "\n",
    "                slice_and_accumulate(iyear, imonth, iday, log_file)\n",
    "\n",
    "    log_file.write(\"Processing completed.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "219ba10b-36e9-478f-a548-2ad83753d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCATENATED DAILY ACCUMULATED .NC FILES INTO MONTHLY ACCUMULATED RAINFALLDATA IN .NC \n",
    "#(CODE FOR LOG FILE:Log_2022_Monthly_accumulated.txt) \n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the directory containing the daily .nc files\n",
    "directory = \"/home/pc/Desktop/IMERG_OP_2022\"\n",
    "output_base_path = directory\n",
    "log_file_path = os.path.join(output_base_path, \"log_2022_Monthly_accumulated.txt\")\n",
    "\n",
    "# Open the log file\n",
    "with open(log_file_path, 'w') as log_file:\n",
    "    # Write the title to the log file\n",
    "    log_file.write(\"MONTHLY_ACCUMULATED_YEAR 2022\\n\\n\")\n",
    "\n",
    "    # Define the range of months to process\n",
    "    months = [\"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\"]\n",
    "    year = \"2022\"\n",
    "\n",
    "    # Function to process each month\n",
    "    def process_month(month):\n",
    "        daily_datasets = []\n",
    "\n",
    "        # Determine the number of days in the month\n",
    "        num_days = pd.Period(year + \"-\" + month).days_in_month\n",
    "        log_file.write(f\"Processing month: {month}, Number of days: {num_days}\\n\")\n",
    "\n",
    "        # Load daily files for the given month\n",
    "        for day in range(1, num_days + 1):\n",
    "            file_path = os.path.join(directory, f\"IMERG_Daily_acc_rainfall_{year}-{month}-{day:02d}.nc\")\n",
    "            log_file.write(f\"Opening file: {file_path}\\n\")\n",
    "            \n",
    "            try:\n",
    "                with xr.open_dataset(file_path) as nc_file:\n",
    "                    log_file.write(f\"Contents of {file_path}:\\n{nc_file}\\n\")\n",
    "                    daily_datasets.append(nc_file)\n",
    "            except Exception as e:\n",
    "                log_file.write(f\"Failed to open file {file_path}: {e}\\n\")\n",
    "                continue\n",
    "\n",
    "        # Combine daily datasets into a single monthly dataset\n",
    "        log_file.write(f\"Combining daily datasets for month: {month}\\n\")\n",
    "        monthly_ds = xr.concat(daily_datasets, dim=\"time\")\n",
    "\n",
    "        # Ensure the time dimension remains consistent\n",
    "        time_values = [pd.to_datetime(str(t.values)) for t in monthly_ds['time']]\n",
    "        monthly_ds['time'] = time_values\n",
    "        log_file.write(f\"Updated time dimension for month: {month}\\n\")\n",
    "\n",
    "        # Rename the time dimension to day\n",
    "        monthly_ds = monthly_ds.rename({'time': 'day'})\n",
    "        log_file.write(f\"Renamed time dimension to day for month: {month}\\n\")\n",
    "\n",
    "        # Save the combined dataset to a new .nc file\n",
    "        output_path = os.path.join(directory, f\"Daily_3gmt_to_3gmt_accumulated_rainfall_{year}-{month}_{1}-{num_days}.nc\")\n",
    "        monthly_ds.to_netcdf(output_path)\n",
    "        log_file.write(f\"Saved combined dataset to: {output_path}\\n\")\n",
    "\n",
    "        # Log the saved file and its contents\n",
    "        log_file.write(f\"Opening and logging contents of {output_path}\\n\")\n",
    "        try:\n",
    "            with xr.open_dataset(output_path) as nc_file:\n",
    "                log_file.write(f\"Contents of {output_path}:\\n{nc_file}\\n\")\n",
    "                log_file.write(\"Accumulated Precipitation Values:\\n\")\n",
    "                \n",
    "                # Assuming 'accumulated_precipitation' is the variable name\n",
    "                if 'accumulated_precipitation' in nc_file:\n",
    "                    log_file.write(str(nc_file['accumulated_precipitation'].values))\n",
    "                else:\n",
    "                    log_file.write(\"Variable 'accumulated_precipitation' not found in the dataset.\\n\")\n",
    "                \n",
    "                log_file.write('\\n')\n",
    "        except Exception as e:\n",
    "            log_file.write(f\"Error opening and logging contents of {output_path}: {e}\\n\")\n",
    "\n",
    "    # Process each month in the specified range\n",
    "    for month in months:\n",
    "        process_month(month)\n",
    "\n",
    "    log_file.write(\"All months processed.\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
